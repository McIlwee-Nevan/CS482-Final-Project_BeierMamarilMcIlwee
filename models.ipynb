{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/McIlwee-Nevan/CS482-Final-Project_BeierMamarilMcIlwee/blob/main/models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rtatman/deceptive-opinion-spam-corpus\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQHEgK1dFDWa",
        "outputId": "567670eb-bd52-4d4f-e38a-2513880fe8a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rtatman/deceptive-opinion-spam-corpus?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456k/456k [00:00<00:00, 50.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/rtatman/deceptive-opinion-spam-corpus/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EbqW6HY_eDT"
      },
      "source": [
        "Import Dataset and Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tbf8eM3a_eDV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(path+\"/deceptive-opinion.csv\")\n",
        "X = np.copy(data['text'])\n",
        "y = np.copy(data['deceptive'])\n",
        "y = np.array(y == 'truthful').astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nreddAGk_eDW"
      },
      "source": [
        "Next, build and evaluate the models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wkDR3II6_eDX",
        "outputId": "0320b61f-8765-4c85-ab56-78b87bfabbf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Accuracy: 0.8500\n",
            "Linear Regression Precision: 0.8846, Recall: 0.8214, F1 Score: 0.8519\n",
            "\n",
            "\n",
            "Decision Tree Accuracy: 0.7219\n",
            "Decision Tree Precision: 0.7365, Recall: 0.7321, F1 Score: 0.7343\n",
            "\n",
            "\n",
            "Random Forest Accuracy: 0.8406\n",
            "Random Forest Precision: 0.8874, Recall: 0.7976, F1 Score: 0.8401\n",
            "\n",
            "\n",
            "XGBoost Accuracy: 0.7969\n",
            "XGBoost Precision: 0.8160, Recall: 0.7917, F1 Score: 0.8036\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = [\n",
        "    LinearRegression(),\n",
        "    DecisionTreeClassifier(max_depth=10),\n",
        "    RandomForestClassifier(max_depth=20),\n",
        "    XGBClassifier()\n",
        "]\n",
        "\n",
        "# Define classifier labels\n",
        "classifier_labels = ['Linear Regression', 'Decision Tree', 'Random Forest', 'XGBoost']\n",
        "\n",
        "accuracies = np.zeros(4)\n",
        "precision = np.zeros(4)\n",
        "recall = np.zeros(4)\n",
        "f1 = np.zeros(4)\n",
        "\n",
        "index = 0\n",
        "for model in classifiers:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if isinstance(model, LinearRegression):\n",
        "        for i in range(len(y_pred)):\n",
        "            y_pred[i] = 1 if y_pred[i] > 0.5 else 0\n",
        "        accuracies[index] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "        precision_score, recall_score, f1_score, support_score = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='binary')\n",
        "        precision[index] = precision_score\n",
        "        recall[index] = recall_score\n",
        "        f1[index] = f1_score\n",
        "        print(f'{classifier_labels[index]} Accuracy: {accuracies[index]:.4f}')\n",
        "        print(f'{classifier_labels[index]} Precision: {precision[index]:.4f}, Recall: {recall[index]:.4f}, F1 Score: {f1[index]:.4f}')\n",
        "    else:\n",
        "        accuracies[index] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "        precision_score, recall_score, f1_score, support_score = precision_recall_fscore_support(y_true=y_test, y_pred=y_pred, average='binary')\n",
        "        precision[index] = precision_score\n",
        "        recall[index] = recall_score\n",
        "        f1[index] = f1_score\n",
        "        print(f'{classifier_labels[index]} Accuracy: {accuracies[index]:.4f}')\n",
        "        print(f'{classifier_labels[index]} Precision: {precision[index]:.4f}, Recall: {recall[index]:.4f}, F1 Score: {f1[index]:.4f}')\n",
        "    print('\\n')\n",
        "    index += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and Test Neural Network"
      ],
      "metadata": {
        "id": "DbAXC9aMfD_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "NLkeg-b5fGOn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "QJff4ro_oBF6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors from data set, create data loaders\n",
        "X_train_tensor = torch.from_numpy(X_train.todense()).to(torch.float32)\n",
        "X_test_tensor = torch.from_numpy(X_test.todense()).to(torch.float32)\n",
        "y_train_tensor = torch.from_numpy(y_train)\n",
        "y_test_tensor = torch.from_numpy(y_test)\n",
        "\n",
        "train_loader = DataLoader(list(zip(X_train_tensor, y_train_tensor)), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(list(zip(X_test_tensor, y_test_tensor)), batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "0jLixnw7oBU9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8YCxJpGUZRDM"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_dim : int):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, 400)\n",
        "        self.fc2 = nn.Linear(400, 200)\n",
        "        self.fc3 = nn.Linear(200, 100)\n",
        "        self.fc4 = nn.Linear(100, 2)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.relu(self.fc2(out))\n",
        "        out = self.relu(self.fc3(out))\n",
        "        out = self.relu(self.fc4(out))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model and choose criterion/optimizer\n",
        "nn_model = NeuralNet(8703)\n",
        "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "G6MfJF0_oVyg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "num_epochs = 10\n",
        "loss_arr = np.zeros(num_epochs)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    nn_model.train()\n",
        "\n",
        "    for (x, y) in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        z = nn_model.forward(x)\n",
        "        loss = criterion(z, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "    loss_arr[epoch] = loss.item()"
      ],
      "metadata": {
        "id": "W9Fjj-p1od0x",
        "outputId": "3f6c4e28-d66b-4579-d67e-ec0363607112",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6720\n",
            "Epoch [2/10], Loss: 0.2862\n",
            "Epoch [3/10], Loss: 0.0021\n",
            "Epoch [4/10], Loss: 0.0049\n",
            "Epoch [5/10], Loss: 0.0026\n",
            "Epoch [6/10], Loss: 0.0002\n",
            "Epoch [7/10], Loss: 0.0001\n",
            "Epoch [8/10], Loss: 0.0001\n",
            "Epoch [9/10], Loss: 0.0001\n",
            "Epoch [10/10], Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for (x, y) in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            z = model(x)\n",
        "            _, predicted = torch.max(z, 1)\n",
        "            y_true.extend(y.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "bWnm0PC7oi79"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy and print report\n",
        "y_true, y_pred = evaluate_model(nn_model, test_loader)\n",
        "print(\"Classification Report: \\n\", classification_report(y_true, y_pred))\n",
        "print(\"Accuracy: \", accuracy_score(y_true, y_pred))"
      ],
      "metadata": {
        "id": "Pyx5jiIFo1kT",
        "outputId": "df00a1a4-29c0-400e-fc54-a13ac01ee1c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.87       152\n",
            "           1       0.90      0.86      0.88       168\n",
            "\n",
            "    accuracy                           0.88       320\n",
            "   macro avg       0.88      0.88      0.88       320\n",
            "weighted avg       0.88      0.88      0.88       320\n",
            "\n",
            "Accuracy:  0.878125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save epochs, loss, and parameters\n",
        "torch.save({\n",
        "            'epoch': num_epochs,\n",
        "            'model_state_dict': nn_model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss_arr[-1],\n",
        "            }, './nn_model.pt')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('./nn_model.pt')"
      ],
      "metadata": {
        "id": "G2n3ZM5LpA8a",
        "outputId": "9b0029af-867a-4277-9c0d-67c71effcc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_455c8eef-06d6-44ba-8ed5-d45e448aa542\", \"nn_model.pt\", 42994586)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "user_review = input(\"Enter a review: \")\n",
        "\n",
        "user_review = vectorizer.transform([user_review])\n",
        "user_review = torch.from_numpy(user_review.todense()).to(torch.float32)\n",
        "\n",
        "neural_network = NeuralNet(8703)\n",
        "\n",
        "output = neural_network.forward(user_review)\n",
        "\n",
        "probabilities = F.softmax(output, dim=1)\n",
        "\n",
        "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "id": "S0iIptTvSotJ",
        "outputId": "53e66299-9f0c-484e-bb9c-cb5a25d7826f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a review: m a local and I’ve had a few interactions with staff here over the years and every single one has been excellent. The staff here are friendly and genuinely kind and that is honestly such an asset to this location. Shoutout to Mikayla and Ashley for being especially kind and accommodating. I’m truly grateful!\n",
            "1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}